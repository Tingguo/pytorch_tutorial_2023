{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "timestep = 1 # time window size\n",
    "batch_size = 16\n",
    "input_dim = 14\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "num_layers = 3\n",
    "epochs = 10\n",
    "best_loss = 0\n",
    "model_name = 'gru'\n",
    "save_path = './{}.pth'.format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01.01.2009 00:10:00</th>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01.01.2009 00:20:00</th>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01.01.2009 00:30:00</th>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01.01.2009 00:40:00</th>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01.01.2009 00:50:00</th>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "Date Time                                                                \n",
       "01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
       "01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
       "01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
       "01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
       "01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
       "\n",
       "                     VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  \\\n",
       "Date Time                                                                  \n",
       "01.01.2009 00:10:00          3.33          3.11          0.22       1.94   \n",
       "01.01.2009 00:20:00          3.23          3.02          0.21       1.89   \n",
       "01.01.2009 00:30:00          3.21          3.01          0.20       1.88   \n",
       "01.01.2009 00:40:00          3.26          3.07          0.19       1.92   \n",
       "01.01.2009 00:50:00          3.27          3.08          0.19       1.92   \n",
       "\n",
       "                     H2OC (mmol/mol)  rho (g/m**3)  wv (m/s)  max. wv (m/s)  \\\n",
       "Date Time                                                                     \n",
       "01.01.2009 00:10:00             3.12       1307.75      1.03           1.75   \n",
       "01.01.2009 00:20:00             3.03       1309.80      0.72           1.50   \n",
       "01.01.2009 00:30:00             3.02       1310.24      0.19           0.63   \n",
       "01.01.2009 00:40:00             3.08       1309.19      0.34           0.50   \n",
       "01.01.2009 00:50:00             3.09       1309.00      0.32           0.63   \n",
       "\n",
       "                     wd (deg)  \n",
       "Date Time                      \n",
       "01.01.2009 00:10:00     152.3  \n",
       "01.01.2009 00:20:00     136.1  \n",
       "01.01.2009 00:30:00     171.6  \n",
       "01.01.2009 00:40:00     198.0  \n",
       "01.01.2009 00:50:00     214.3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load data\n",
    "df = pd.read_csv('./data/jena_climate_2009_2016.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0740129 ],\n",
       "       [-2.12031274],\n",
       "       [-2.1321845 ],\n",
       "       ...,\n",
       "       [-1.49704566],\n",
       "       [-1.62407343],\n",
       "       [-1.69411678]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. standardize data\n",
    "scaler = StandardScaler()\n",
    "scaler_model = StandardScaler()\n",
    "data = scaler_model.fit_transform(np.array(df))\n",
    "scaler.fit_transform(np.array(df['T (degC)']).reshape(-1,1))   # T (degC) is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. generate training data, like 1234 -> 5, 2345 -> 6, ...\n",
    "def split_data(data, timestep, input_dim):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "\n",
    "    for index in range(len(data) - timestep):\n",
    "        dataX.append(data[index:index+timestep])\n",
    "        dataY.append(data[index+timestep][1])\n",
    "    \n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)\n",
    "\n",
    "    # get training data size\n",
    "    train_size = int(np.round(0.8*dataX.shape[0]))\n",
    "    # split data into training and testing\n",
    "    x_train = dataX[:train_size,:].reshape(-1,timestep,input_dim)\n",
    "    y_train = dataY[:train_size]\n",
    "\n",
    "    x_test = dataX[train_size:,:].reshape(-1,timestep,input_dim)\n",
    "    y_test = dataY[train_size:]\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. getting training data\n",
    "x_train, y_train, x_test, y_test = split_data(data, timestep, input_dim)\n",
    "\n",
    "# 5. turn to TensorDataset\n",
    "x_train_tensor = torch.from_numpy(x_train).to(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(y_train).to(torch.float32)\n",
    "x_test_tensor = torch.from_numpy(x_test).to(torch.float32)\n",
    "y_test_tensor = torch.from_numpy(y_test).to(torch.float32)\n",
    "\n",
    "# 6. generate dataloader\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. define GRU model\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,output_dim):\n",
    "        super(GRU,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers # LSTM layers\n",
    "        self.gru = nn.GRU(input_dim,hidden_dim,num_layers,batch_first=True) # batch_first means (batch, seq, feature)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output, h_n = self.gru(x) # output size: (batch, seq, hidden_dim)\n",
    "        batch_size, timestep, hidden_dim = output.shape\n",
    "\n",
    "        output = output.reshape(-1,hidden_dim)\n",
    "        output = self.fc(output)\n",
    "        output = output.reshape(timestep, batch_size,-1) # (timestep, batch, output_dim)\n",
    "\n",
    "        return output[-1] # (batch, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_dim,hidden_dim,num_layers,output_dim)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/10] loss:0.004: 100%|██████████| 21028/21028 [01:02<00:00, 338.15it/s]\n",
      "train epoch[2/10] loss:0.001: 100%|██████████| 21028/21028 [01:01<00:00, 340.62it/s]\n",
      "train epoch[3/10] loss:0.004: 100%|██████████| 21028/21028 [01:01<00:00, 341.63it/s]\n",
      "train epoch[4/10] loss:0.001: 100%|██████████| 21028/21028 [01:03<00:00, 333.06it/s]\n",
      "train epoch[5/10] loss:0.002: 100%|██████████| 21028/21028 [01:03<00:00, 330.97it/s]\n",
      "train epoch[6/10] loss:0.001: 100%|██████████| 21028/21028 [01:04<00:00, 328.09it/s]\n",
      "train epoch[7/10] loss:0.001: 100%|██████████| 21028/21028 [01:03<00:00, 332.35it/s]\n",
      "train epoch[8/10] loss:0.001: 100%|██████████| 21028/21028 [01:03<00:00, 330.97it/s]\n",
      "train epoch[9/10] loss:0.001: 100%|██████████| 21028/21028 [01:02<00:00, 337.58it/s]\n",
      "train epoch[10/10] loss:0.000: 100%|██████████| 21028/21028 [01:01<00:00, 340.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 8. training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader) # show progress bar\n",
    "    for data in train_bar:\n",
    "        x_train, y_train = data # get data\n",
    "        optimizer.zero_grad() # clear gradient\n",
    "        y_train_pred = model(x_train)\n",
    "        loss = loss_function(y_train_pred,y_train.reshape(-1,1))\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch+1,epochs,loss)\n",
    "\n",
    "    # model evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader)\n",
    "        for data in test_bar:\n",
    "            x_test, y_test = data\n",
    "            y_test_pred = model(x_test)\n",
    "            test_loss = loss_function(y_test_pred,y_test.reshape(-1,1))\n",
    "\n",
    "print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(scaler.inverse_transform((model(x_train_tensor).detach().numpy()).reshape(-1,1)),\"b\")\n",
    "plt.plot(scaler.inverse_transform(y_train_tensor.detach().numpy().reshape(-1,1)),\"r\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_test_pred = model(x_test_tensor)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(scaler.inverse_transform(y_test_pred.detach().numpy()),\"b\")\n",
    "plt.plot(scaler.inverse_transform(y_test_tensor.detach().numpy().reshape(-1,1)),\"r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
